{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The transformer architecture\n",
    "\n",
    "The transformer architecture describes an Encoder (left) and Decoder (right).\n",
    "\n",
    "<img src=\"assets/transformer.png\" alt=\"Image\" style=\"width:20%; display: block; margin: 0 auto;\"/>\n",
    "\n",
    "## Encoder\n",
    "- Encodes words or word-tokens to vectors. One input word/token results in one output word/token vector.\n",
    "- All words are simultaniously passed into the encoder. This has several advantages e.g., usage of parallelization on GPUs and better captioning of word meaning through the attention block.\n",
    "\n",
    "#### Encoder Blocks\n",
    "- Input Embedding: Some vector embedding of each word.\n",
    "- Positional Encoding: Encoding of each word with respect to the position of the word in a sentence.\n",
    "- Input Embedding and Positional Encoding forms the Input to the Encoder Block.\n",
    "- Multi-Head Attention: Every single word has 3 vectors: Q, K and V. More explanation below. \"Multi\" because we can stack the results on top of each other to get multi-attention. \n",
    "    - Q = What I am looking for [sequence length x d<sub>k</sub>].\n",
    "    - K = What I can offer [sequence length x d<sub>k</sub>]\n",
    "    - V: What I actually offer [sequence length x d<sub>v</sub>]\n",
    "- Feed Forward:\n",
    "- Add & Norm:\n",
    "\n",
    "## Decoder\n",
    "- The decoder first takes in the output of the encoder and a start token.\n",
    "- Then it will start generating the first word e.g. a translated word.\n",
    "- The translated word is then taken as an input for the decoder to generate the next word until the end of the sequence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attention (Single Attention Head Logic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length, d_k, d_v = 4, 8, 8\n",
    "q = np.random.randn(sequence_length, d_k) # creates 8 x 1 vectors for each word in the sequence\n",
    "k = np.random.randn(sequence_length, d_k) # creates 8 x 1 vectors for each word in the sequence\n",
    "v = np.random.randn(sequence_length, d_v) # creates 8 x 1 vectors for each word in the sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q: [[ 0.86868105  0.08988912 -1.10323393  0.93144423 -0.22112637 -0.24831209\n",
      "   0.40688423 -0.91289303]\n",
      " [ 0.40834656  0.50665297  0.4314858   0.53812964 -0.16228728  1.2091965\n",
      "   0.32464194  1.24150235]\n",
      " [-1.4595666   0.42829345 -2.01205567 -0.54580935 -0.25461517  0.45080158\n",
      "   0.97421065 -0.31558105]\n",
      " [ 0.0123245   0.15119283  0.47036     0.82814215 -0.77944948  0.22135308\n",
      "  -0.05344812 -0.17976496]]\n",
      "k: [[-0.14663854  0.17277554  0.52508051 -0.9774565   0.67674323  2.12405684\n",
      "   1.9797991   0.25068627]\n",
      " [ 0.62117261 -0.01769471  0.62455526  0.63756487  0.45165196  0.40678757\n",
      "   0.2247856   0.61074585]\n",
      " [ 0.98421635 -0.08212173 -0.52603783 -0.51968416  0.03170745  0.77673048\n",
      "  -0.09899019 -0.26064771]\n",
      " [-0.00777449 -0.3075334   0.35970135  1.77996769  1.26058828 -1.26232102\n",
      "  -0.67460475 -0.19517895]]\n",
      "v: [[-0.06308092 -0.65323852 -0.31715511  0.02395267 -0.30154605  0.90656808\n",
      "  -0.71534914 -0.52487617]\n",
      " [-1.90357465  1.51662128  0.37612027  0.15376715  1.36739678 -1.5665135\n",
      "  -0.19630905  0.81053136]\n",
      " [-0.97739     0.74075609 -0.82804033  1.40544962 -1.02485925 -1.64379155\n",
      "   2.05146446  1.10501159]\n",
      " [-0.14507501  0.19830393  0.15942467 -0.9864518   0.55839545  0.47173279\n",
      "   0.0833837  -1.19999508]]\n"
     ]
    }
   ],
   "source": [
    "print(\"q:\", q)\n",
    "print(\"k:\", k)  \n",
    "print(\"v:\", v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Self-Attention\n",
    "\n",
    "<img src=\"assets/attention.png\" alt=\"Image\" style=\"width:20%; display: block; margin: 0 auto;\"/>\n",
    "\n",
    "\n",
    "$$\n",
    "\\text{Self-Attention}(Q, K, V) = \\text{softmax}\\left(\\frac{QK^T}{\\sqrt{d_k}}\\right)V\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.70195981, -0.22413047,  0.94165722,  1.16510018],\n",
       "       [ 3.14075306,  2.1070739 ,  0.43200179, -1.23821972],\n",
       "       [ 2.39988965, -2.4242184 ,  0.19826067, -3.30126287],\n",
       "       [-0.74638268,  0.44293921, -0.47872225,  0.40582191]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create an initial attention matrix, we need every word to look at every word to look at every other word \n",
    "np.matmul(q, k.T) # 4 x 4 matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.60173366, -0.07924209,  0.3329261 ,  0.41192512],\n",
       "       [ 1.11042389,  0.74496312,  0.1527357 , -0.43777678],\n",
       "       [ 0.84848912, -0.85709064,  0.07009573, -1.16717268],\n",
       "       [-0.26388613,  0.15660266, -0.16925388,  0.14347971]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled = np.matmul(q, k.T) / math.sqrt(d_k) # scale by square root of d_k\n",
    "scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Masking\n",
    "- This is to ensure words don't get context from words generated in the future\n",
    "- Not requred in the encoders, but reqiured in the decoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0.],\n",
       "       [1., 1., 0., 0.],\n",
       "       [1., 1., 1., 0.],\n",
       "       [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = np.tril(np.ones((sequence_length, sequence_length)))\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0., -inf, -inf, -inf],\n",
       "       [  0.,   0., -inf, -inf],\n",
       "       [  0.,   0.,   0., -inf],\n",
       "       [  0.,   0.,   0.,   0.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask[mask == 0] = -np.infty\n",
    "mask[mask == 1.0] = 0\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.60173366,        -inf,        -inf,        -inf],\n",
       "       [ 1.11042389,  0.74496312,        -inf,        -inf],\n",
       "       [ 0.84848912, -0.85709064,  0.07009573,        -inf],\n",
       "       [-0.26388613,  0.15660266, -0.16925388,  0.14347971]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled + mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax\n",
    "- Is used to convert a vector into a probability distribution\n",
    "- Advantage: Values add up to one and are more interpretable\n",
    "\n",
    "$$\n",
    "\\text{softmax}(x) = \\frac{e^{x_i}}{\\sum_j e_j^x}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    return np.exp(x) / np.sum(np.exp(x), axis=1).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.        , 0.        , 0.        ],\n",
       "       [5.54090339, 0.40963831, 0.        , 0.        ],\n",
       "       [4.26406437, 0.08253487, 0.27982707, 0.        ],\n",
       "       [1.40192674, 0.2274463 , 0.22026298, 0.29325041]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention = softmax(scaled + mask)\n",
    "attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.06308092, -0.65323852, -0.31715511,  0.02395267, -0.30154605,\n",
       "         0.90656808, -0.71534914, -0.52487617],\n",
       "       [-1.12930238, -2.99826537, -1.60325255,  0.19570834, -1.1106994 ,\n",
       "         4.3815022 , -4.04409616, -2.57626344],\n",
       "       [-0.69959256, -2.45299337, -1.55303486,  0.50810972, -1.4597372 ,\n",
       "         3.27639529, -2.49244182, -1.86199652],\n",
       "       [-0.77922197, -0.34952881, -0.49471635,  0.08884478, -0.17372499,\n",
       "         0.69091375, -0.57120287, -0.65999148]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# multiplie attention matrix with value matrix\n",
    "new_v = np.matmul(attention, v)\n",
    "new_v # new matrix which should encapsulate the context of a word better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.06308092, -0.65323852, -0.31715511,  0.02395267, -0.30154605,\n",
       "         0.90656808, -0.71534914, -0.52487617],\n",
       "       [-1.90357465,  1.51662128,  0.37612027,  0.15376715,  1.36739678,\n",
       "        -1.5665135 , -0.19630905,  0.81053136],\n",
       "       [-0.97739   ,  0.74075609, -0.82804033,  1.40544962, -1.02485925,\n",
       "        -1.64379155,  2.05146446,  1.10501159],\n",
       "       [-0.14507501,  0.19830393,  0.15942467, -0.9864518 ,  0.55839545,\n",
       "         0.47173279,  0.0833837 , -1.19999508]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-head Attention\n",
    "- Takes a vector (e.g. 512x1) which breaks down into three vectors (Q, K and V). \n",
    "- These three vectors are broken up into separate pieces e.g. 8 pieces for 8 attention heads\n",
    "- Each of these pieces is fed into an **Attention Unit** with all the other words too\n",
    "- This genereates an attention matrix for each head which is of size sequence length to sequence length. Moreover all rows add up to one, because its a probability distribution.\n",
    "- This generates other output vectors that get concatenated, which generates a vector with very good contextual awareness\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = 4 # length of input sentence with fixed max size\n",
    "batch_size = 1 \n",
    "input_dim = 512 # vector dimension of every word that goes into the attention unit \n",
    "d_model = 512 # output of the attention unit for every word\n",
    "x = torch.randn(batch_size, sequence_length, input_dim) # input embedding randomly generated from a normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 512])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mapping of the input dimension to the Q, K and V vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "qkv_layer = nn.Linear(input_dim, d_model * 3) # linear layer to generate q, k, v vectors all concatenated together, which all have 8 attention heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "qkv = qkv_layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 1536])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qkv.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is 1 batch, 4 words, with each word vector being 1536 in size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.5720, -0.4355, -0.6658,  ...,  0.3326,  0.1917,  0.3432],\n",
       "        [ 0.7264, -1.0669, -0.4281,  ..., -0.9502, -1.2488, -0.8482],\n",
       "        [ 0.5239, -0.8063, -0.5243,  ...,  0.3656, -0.0138, -0.7699],\n",
       "        [ 0.5537, -0.0665, -0.8164,  ...,  0.1043, -0.2839,  0.6794]],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qkv[0] # this is the batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.5720, -0.4355, -0.6658,  ...,  0.3326,  0.1917,  0.3432],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qkv[0][0] # this is the vector of the batch and the first word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'qkv distribution')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "y_val = torch.histc(qkv, bins=200, min=-3, max=3)\n",
    "x_val = np.arange(-1, 1, 0.01) * 3\n",
    "plt.bar(x_val, y_val, align='center')\n",
    "plt.title('qkv distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_heads = 8\n",
    "head_dim = d_model // num_heads\n",
    "qkv = qkv.reshape(batch_size, sequence_length, num_heads, 3 * head_dim) # breaks down last dimension into a product of num_heads and 3 * head_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "192"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(512 // 8) * 3 # 3 for q, k, v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 8, 192])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qkv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([192])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qkv[0][0][0].size() # first batch, first word, first attention head with all q, k, v vectors concatenated, each being of size 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 4, 192])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qkv = qkv.permute(0, 2, 1, 3) # [batch_size, num_heads, sequence_length, 3*head_dim]\n",
    "qkv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 8, 4, 64]),\n",
       " torch.Size([1, 8, 4, 64]),\n",
       " torch.Size([1, 8, 4, 64]))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q, k, v = qkv.chunk(3, dim=-1) # splits the last dimension into 3 chunks, each of size 64\n",
    "q.shape, k.shape, v.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Self-Attention for multiple heads\n",
    "\n",
    "For a single head:\n",
    "\n",
    "$$\n",
    "\\text{Self-Attention}(Q, K, V) = \\text{softmax}\\left(\\frac{QK^T}{\\sqrt{d_k}} + M\\right)\n",
    "$$\n",
    "$$\n",
    "\\text{new V} = \\text{Self-Attention. V}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every word has a query vector and it is going to compare itslef to one of its key vectors i.e. the matrix multiplication of \n",
    "$$QK^T$$\n",
    "We scale this by \n",
    "$$\\sqrt{d_k}$$ \n",
    "to make sure that the variance of the values is much smaller."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 4, 4])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_k = q.size()[-1]\n",
    "scaled = torch.matmul(q, k.transpose(-2, -1)) / math.sqrt(d_k) # transpose along the sequence length and the dimension size (head_dim) scaled by square root of d_k\n",
    "scaled.shape # sequence_length x sequence_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 4, 8, 1])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k.T.shape # sequence_length x sequence_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., -inf, -inf, -inf],\n",
       "        [0., 0., -inf, -inf],\n",
       "        [0., 0., 0., -inf],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = torch.full(scaled.size(), float('-inf')) # create a matrix of negative infinity\n",
    "mask = torch.triu(mask, diagonal=1) # create a upper triangular matrix of negative infinity\n",
    "mask[0][1] # mask for input to a single head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0676,    -inf,    -inf,    -inf],\n",
       "        [-0.0658, -0.1217,    -inf,    -inf],\n",
       "        [-0.1628, -0.7305,  0.0187,    -inf],\n",
       "        [-0.2241, -0.3892,  0.3594,  0.0204]], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(scaled + mask)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled += mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention = F.softmax(scaled, dim=-1) # softmax along the last dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 4, 4])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.5140, 0.4860, 0.0000, 0.0000],\n",
       "        [0.3615, 0.2049, 0.4335, 0.0000],\n",
       "        [0.2034, 0.1724, 0.3645, 0.2597]], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 4, 64])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values = torch.matmul(attention, v) # multiply attention with v (what is offered by every single word)\n",
    "values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 512])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values = values.reshape(batch_size, sequence_length, num_heads * head_dim) # concatenate all the heads together\n",
    "values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_layer = nn.Linear(d_model, d_model) # linear layer to transform the concatenated heads into the output dimension to 512 x 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = linear_layer(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 512])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.2428,  0.2622,  0.1467,  ...,  0.1397, -0.1031,  0.3395],\n",
       "         [-0.2548, -0.0433,  0.1523,  ...,  0.3486, -0.2958, -0.2404],\n",
       "         [ 0.0026, -0.3175, -0.0807,  ..., -0.3405,  0.3318,  0.1761],\n",
       "         [-0.3646, -0.1380,  0.1150,  ..., -0.5668,  0.0620, -0.1288]]],\n",
       "       grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out # new vectors for each word of a sequence which should be more context aware than the original vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Positional Encoding\n",
    "\n",
    "- Inital part of the transformer neural network architecture\n",
    "- Take the sequence and pad the rest to the max allowed sequence length of the network\n",
    "- Each word is one-hot encoded, where vocab size is the number of words in the dictionary (all possible words that can be used as input)\n",
    "- This is passed into a feed-forward layer where each of these vectors is mapped to a 512 dimensional vector. Parameters are learnable via backpropagation.\n",
    "- Output is a set of 512 dimensional vectors for each input in the sequence\n",
    "- To the output a set of positional encoded vectors is added, which then forms the input into the next steps of the transformer network\n",
    "\n",
    "<img src=\"assets/positional_encoding.png\" alt=\"Image\" style=\"width:20%; display: block; margin: 0 auto;\"/>\n",
    "\n",
    "- i = dimension index\n",
    "- d_model = Embedding Length\n",
    "- pos = position of word in sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sequence_length = 10\n",
    "d_model = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 2., 4.])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "even_i = torch.arange(0, d_model, 2).float() # set of values between 0 and d_model with a step size of 2\n",
    "even_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  1.0000,  21.5443, 464.1590])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "even_denominator = torch.pow(10000, even_i / d_model)\n",
    "even_denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 3., 5.])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "odd_i = torch.arange(1, d_model, 2).float()\n",
    "odd_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  1.0000,  21.5443, 464.1590])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "odd_denominator = torch.pow(10000, (odd_i -1) / d_model)\n",
    "odd_denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "denominator = even_denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "position = torch.arange(max_sequence_length, dtype=torch.float).reshape(max_sequence_length, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.],\n",
       "        [1.],\n",
       "        [2.],\n",
       "        [3.],\n",
       "        [4.],\n",
       "        [5.],\n",
       "        [6.],\n",
       "        [7.],\n",
       "        [8.],\n",
       "        [9.]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "even_PE = torch.sin(position / denominator)\n",
    "odd_PE = torch.cos(position / denominator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000,  0.0000],\n",
       "        [ 0.8415,  0.0464,  0.0022],\n",
       "        [ 0.9093,  0.0927,  0.0043],\n",
       "        [ 0.1411,  0.1388,  0.0065],\n",
       "        [-0.7568,  0.1846,  0.0086],\n",
       "        [-0.9589,  0.2300,  0.0108],\n",
       "        [-0.2794,  0.2749,  0.0129],\n",
       "        [ 0.6570,  0.3192,  0.0151],\n",
       "        [ 0.9894,  0.3629,  0.0172],\n",
       "        [ 0.4121,  0.4057,  0.0194]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "even_PE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 3, 2])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked = torch.stack((even_PE, odd_PE), dim=2)\n",
    "stacked.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  1.0000,  0.0000,  1.0000,  0.0000,  1.0000],\n",
       "        [ 0.8415,  0.5403,  0.0464,  0.9989,  0.0022,  1.0000],\n",
       "        [ 0.9093, -0.4161,  0.0927,  0.9957,  0.0043,  1.0000],\n",
       "        [ 0.1411, -0.9900,  0.1388,  0.9903,  0.0065,  1.0000],\n",
       "        [-0.7568, -0.6536,  0.1846,  0.9828,  0.0086,  1.0000],\n",
       "        [-0.9589,  0.2837,  0.2300,  0.9732,  0.0108,  0.9999],\n",
       "        [-0.2794,  0.9602,  0.2749,  0.9615,  0.0129,  0.9999],\n",
       "        [ 0.6570,  0.7539,  0.3192,  0.9477,  0.0151,  0.9999],\n",
       "        [ 0.9894, -0.1455,  0.3629,  0.9318,  0.0172,  0.9999],\n",
       "        [ 0.4121, -0.9111,  0.4057,  0.9140,  0.0194,  0.9998]])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PE = torch.flatten(stacked, start_dim=1, end_dim=2)\n",
    "PE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layer Normalization (Add & Norm)\n",
    "\n",
    "- Adds the initial embedding (to counteract vanishing gradients during backpropagation) and the output of the attention block and normalizes the result\n",
    "- Normalization: Encapsulates values within smaller range centering around zero --> more even steps in gradient descent, faster and more stable to get to optimal parameter values\n",
    "- Layer: Strategy of Normalization, meaning that all activation values in every layer is normalized such that all values in a layer center around zero and have a standard deviation of about 1\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-transformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
